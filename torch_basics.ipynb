{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  9., 17.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 17, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(-10, 10, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14883637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rand1 @ rand2\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'{end-start:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rand1 = torch.rand(100,100, 100,100).to(device)\n",
    "rand2 = torch.rand(100,100,100,100).to(device)\n",
    "\n",
    "x = rand1 @ rand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.tensor([0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.9000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = torch.multinomial(prob,num_samples=10, replacement=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "tesnor = torch.cat((x,torch.tensor([3])), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesnor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7792, 0.0000, 0.0000],\n",
       "        [0.9910, 0.7106, 0.0000],\n",
       "        [0.0118, 0.4734, 0.2907]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.rand(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([1, 2,3])\n",
    "c = torch.tensor([1, 2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor([10.,10.,10.])\n",
    "\n",
    "lm = nn.Linear(3,3,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.5261,   0.9135,  -5.4973], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(lm(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SumanPaudel\\AppData\\Local\\Temp\\ipykernel_5928\\3297064524.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(tesnor1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesnor1 = torch.tensor([1.0,2.0,3.0])\n",
    "\n",
    "F.softmax(tesnor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(tesnor1) / torch.sum(torch.exp(tesnor1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "vector_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0968e+00, -4.0924e-01, -2.3089e-01,  9.4508e-01,  9.9422e-01,\n",
       "          3.9063e-01, -2.7686e-02, -1.1837e+00, -1.1361e-01, -6.1671e-01,\n",
       "          3.0849e-01,  2.3612e-01, -7.3841e-01,  3.7551e-01,  2.4190e-01,\n",
       "         -9.8400e-01,  1.2928e+00,  1.4958e+00, -3.9880e-01,  1.7212e+00,\n",
       "         -4.4725e-01,  7.0387e-01,  4.8873e-01, -1.9324e+00,  2.4552e+00,\n",
       "          5.1241e-01, -1.1888e+00,  9.4284e-02, -2.5499e-01, -1.3225e+00,\n",
       "          1.8600e-01, -6.6936e-01,  4.5975e-01, -2.9469e-01,  1.9163e+00,\n",
       "         -7.9657e-01, -1.3408e+00,  5.6323e-01,  7.1427e-02,  1.6137e+00,\n",
       "          6.0415e-01,  4.3579e-01,  8.0884e-02, -2.9568e-01,  7.6578e-01,\n",
       "          1.0005e+00,  2.5799e-01, -1.8353e-01,  6.2589e-02, -8.1081e-02,\n",
       "         -4.9255e-01, -2.0830e-02, -1.2456e-01,  6.4148e-03,  8.1993e-01,\n",
       "          1.8179e-01,  1.3259e-01,  7.2159e-01, -5.0773e-01, -3.6228e-02,\n",
       "         -4.1866e-01, -4.3410e-01, -2.8222e+00,  2.8133e-01, -1.3397e+00,\n",
       "         -9.3170e-01,  1.1954e+00, -5.4092e-01, -2.1846e+00,  9.0989e-01,\n",
       "         -1.0356e+00,  6.1449e-01, -5.5807e-01, -1.3085e+00,  1.5476e-01,\n",
       "          8.2524e-01, -5.6811e-01, -1.7945e-01,  7.0669e-01, -1.4077e+00,\n",
       "         -1.2348e+00,  5.9636e-01,  1.2196e+00, -1.1522e+00,  4.5175e-01,\n",
       "         -1.1973e+00,  1.2880e+00,  1.2677e+00,  4.2375e-01, -1.0903e-01,\n",
       "         -1.6480e+00, -1.2938e+00, -1.0554e+00, -1.2348e+00, -4.5005e-01,\n",
       "          1.7096e+00,  2.4716e-01,  1.5225e-01,  6.3122e-01, -1.8994e-01],\n",
       "        [ 2.7977e-02, -8.1518e-01, -2.0345e+00,  3.0642e-01,  1.1829e-01,\n",
       "          4.3281e-02,  2.2294e-01,  4.1646e-01,  7.8777e-01,  7.3501e-01,\n",
       "          5.7840e-01,  1.8447e+00, -5.6300e-01,  1.0233e+00,  2.8164e-01,\n",
       "         -5.7973e-01, -8.4339e-01,  1.8271e+00,  2.4362e-01, -6.7389e-01,\n",
       "          4.7448e-03,  3.6069e-01,  5.8239e-01, -1.4388e+00, -1.5462e-01,\n",
       "         -3.1948e-01, -5.1700e-01,  1.3562e+00,  7.4727e-01, -1.1902e-01,\n",
       "         -5.9928e-01, -8.5069e-01,  4.5212e-02, -3.1389e+00, -7.3105e-01,\n",
       "          1.3787e-01, -6.3858e-01,  2.9733e-01, -1.0253e+00, -3.6542e-01,\n",
       "         -6.6412e-02,  9.4976e-01, -2.5890e+00,  8.5271e-01,  1.5563e+00,\n",
       "         -1.2026e+00,  2.4425e-01, -1.3300e+00,  1.0886e+00,  6.2590e-01,\n",
       "         -1.3728e-01,  2.0051e+00,  1.4012e+00, -5.3728e-01,  2.4019e-01,\n",
       "          5.7019e-01,  8.0970e-01,  1.8434e-01,  1.4189e+00, -1.8517e-01,\n",
       "         -2.9728e-02,  2.2848e-01, -9.3174e-01,  1.0039e+00, -6.9131e-01,\n",
       "         -1.3295e-02,  1.5065e-01, -7.9471e-01,  2.2015e+00, -7.5089e-01,\n",
       "          2.0656e+00,  3.6455e-01,  1.6635e+00, -5.8259e-01, -1.7924e+00,\n",
       "          7.2967e-02, -2.0217e+00,  5.0745e-01, -3.1640e-01,  4.1623e-01,\n",
       "         -1.7884e+00,  1.1927e+00,  2.0044e-01, -1.4927e+00, -1.5591e+00,\n",
       "         -5.1327e-01,  5.3423e-01,  3.5390e-01,  2.7584e-01, -1.5282e-01,\n",
       "          5.2961e-01,  9.4024e-01, -7.1934e-01, -3.0487e-01,  8.4641e-02,\n",
       "          8.9284e-01,  8.9360e-01,  5.6823e-01,  1.2432e+00,  1.0127e+00],\n",
       "        [-1.1132e+00,  1.8701e+00,  1.5207e-01, -5.2781e-01, -9.3395e-01,\n",
       "         -7.3444e-01, -1.1828e+00,  2.4431e-01,  4.9012e-01, -1.2887e+00,\n",
       "         -1.3497e+00,  4.2822e-01,  1.0956e-01,  7.9787e-01,  7.3258e-01,\n",
       "          1.0053e+00, -1.1657e+00, -9.4543e-01, -6.0448e-01, -6.8592e-01,\n",
       "          1.2739e+00, -4.5661e-02,  5.3240e-01,  1.3399e+00, -2.9206e-01,\n",
       "          6.2176e-01,  1.4075e-02,  8.6265e-02, -8.4841e-01,  5.7677e-01,\n",
       "          5.9987e-01,  5.1217e-01, -4.5792e-01, -5.3852e-01, -3.4227e-01,\n",
       "         -1.5577e-01,  5.7682e-01,  3.6734e-01, -1.2033e+00, -1.0740e+00,\n",
       "         -2.3859e-01, -9.4074e-01,  1.4466e+00,  1.6304e+00,  5.3035e-01,\n",
       "         -9.8389e-01, -1.2456e+00, -2.1387e-01,  6.5903e-01,  5.3800e-02,\n",
       "          3.7612e-01,  1.4382e-01, -1.0086e-01, -1.2319e+00, -1.2209e+00,\n",
       "         -7.4648e-01, -2.4386e+00, -7.2726e-01,  1.1823e+00, -4.5854e-01,\n",
       "          9.5075e-01, -4.3118e-01,  1.0391e+00, -3.0375e-01,  1.4364e+00,\n",
       "          4.1966e-01, -2.2122e+00,  9.7006e-01, -8.2603e-01,  1.3171e+00,\n",
       "          1.8653e-01,  4.2528e-01, -2.5009e-01,  8.3110e-02,  8.1088e-01,\n",
       "         -2.4855e+00,  6.2244e-01, -7.5160e-01, -1.4808e+00, -1.6572e+00,\n",
       "          1.0438e+00,  1.8124e-01,  8.2164e-01,  1.6852e+00, -4.9315e-01,\n",
       "         -2.0047e+00,  6.9810e-01, -1.1049e+00, -3.8151e-01,  2.4405e+00,\n",
       "          8.0811e-01,  8.8437e-01,  1.1621e+00, -3.1040e-03, -2.7283e-01,\n",
       "         -4.9959e-01, -3.3521e-01, -1.1729e-01,  2.3267e+00, -6.8564e-01],\n",
       "        [ 2.3333e-01, -2.3327e-01,  6.6040e-01, -9.0016e-01, -7.4158e-01,\n",
       "          1.6448e+00,  9.4948e-01, -1.4170e+00,  1.5282e-01,  5.7358e-01,\n",
       "          4.1549e-01, -1.1665e+00,  1.2497e+00,  6.1956e-01, -9.0096e-01,\n",
       "          1.6584e+00, -3.2682e-03, -3.9871e-01, -5.8251e-01, -4.1161e-01,\n",
       "         -2.7726e-01, -6.0502e-01,  8.4303e-01,  9.2057e-01,  8.4527e-01,\n",
       "          2.0517e-02, -5.3707e-01,  4.2986e-02,  3.5837e-01,  7.6992e-03,\n",
       "         -4.8108e-01,  1.1439e+00, -2.7039e-01,  2.2536e-01, -6.0044e-01,\n",
       "          2.1887e-01,  3.4881e-01,  1.5650e+00,  5.3607e-01, -1.2189e+00,\n",
       "          1.0611e+00, -8.3759e-01,  1.0092e-01, -3.2147e-01, -1.3777e-01,\n",
       "         -3.1331e-01, -3.0677e-02,  7.2793e-01, -1.0589e+00,  6.0777e-01,\n",
       "         -5.1857e-01,  1.6010e+00,  5.8235e-02, -7.0438e-01,  8.3922e-01,\n",
       "          8.4642e-02,  1.0047e+00,  3.4530e-01, -1.2113e+00, -1.9170e+00,\n",
       "          1.1754e+00,  6.3050e-01, -4.3591e-02, -4.2361e-01,  1.4493e+00,\n",
       "         -1.0280e-01, -2.9519e+00, -2.3037e-02,  1.9726e+00, -6.9421e-01,\n",
       "          7.7255e-01, -8.9875e-01, -1.2928e+00, -6.9805e-01, -2.7219e+00,\n",
       "          6.3728e-01, -3.6828e-01,  5.3687e-01, -1.4525e+00, -8.1259e-01,\n",
       "         -7.3089e-01,  3.4447e-01,  1.4643e+00,  7.5401e-01, -1.4337e+00,\n",
       "          1.0728e+00, -1.6748e+00,  5.4104e-01,  7.2933e-01,  1.5804e+00,\n",
       "          7.5915e-01, -2.6673e+00, -1.2928e+00, -1.1343e+00, -1.2629e+00,\n",
       "         -3.3540e-01,  1.3940e+00, -9.3622e-01,  1.7968e+00,  1.8493e+00]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.LongTensor([1,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
